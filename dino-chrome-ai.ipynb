{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Installing Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mss pydirectinput pytesseract\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt \n",
    "import time\n",
    "from gym import Env\n",
    "from gym.spaces import Box,Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing tesseract.exe\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating game enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    # Initializing enviroment\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,100), dtype= np.uint8)\n",
    "        \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        self.cap = mss()\n",
    "        self.game_location = {\"top\": 300, \"left\": 0, \"width\":600, \"height\": 500}\n",
    "        self.done_location = {\"top\": 405, \"left\": 630, \"width\":660, \"height\": 70}\n",
    "        \n",
    "    # pass in any actions player might do i.e jump, shoot\n",
    "    def step(self, action):\n",
    "        # mapping actions to keys\n",
    "        action_map = {\n",
    "            0:\"space\",\n",
    "            1:\"down\",\n",
    "            2:\"no_op\"\n",
    "        }\n",
    "        \n",
    "        # passing our map into direct input\n",
    "        if action !=2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "            \n",
    "        #mapping values\n",
    "        done, done_cap = self.get_done()\n",
    "            \n",
    "            \n",
    "        observation = self.get_observation()\n",
    "            \n",
    "        # setting reward\n",
    "        reward = .1 if not done else -1\n",
    "            \n",
    "        info = {}\n",
    "            \n",
    "        return  observation,reward,done,info\n",
    "        \n",
    "    # Reset the game\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150,y=150)\n",
    "        pydirectinput.press(\"space\")\n",
    "        return self.get_observation()\n",
    "            \n",
    "            \n",
    "        \n",
    "    # visualize the game\n",
    "    def render(self):\n",
    "        cv2.imshow(\"Game\",self.current_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                   self.close()\n",
    "                \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "   \n",
    "        \n",
    "    # captures the dinosaur\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        \n",
    "        # Gray scaling image\n",
    "        gray = cv2.cvtColor(raw,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        resized = cv2.resize(gray,(100,83))\n",
    "        channel = np.reshape(resized,(1,83,100))\n",
    "        return channel\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    # is the game over? captures game over screen\n",
    "    def get_done(self):\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))\n",
    "        # game over text\n",
    "        done_strings = [\"GAME\", \"GAHE\"]\n",
    "        done = False\n",
    "        res = pytesseract.image_to_string(done_cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "        return done,done_cap\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing webgame class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return True if \"GAME\" is found in screenshot\n",
    "env.get_done()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.get_done()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-Run Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(10): \n",
    "    obs = env.reset()\n",
    "    done = False  \n",
    "    total_reward   = 0\n",
    "    while not done: \n",
    "        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "        total_reward  += reward\n",
    "    \n",
    "    print(episode, reward)\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create these files in root dir\n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=25000, learning_starts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('train/best_model_100000')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9531468e747e9f19b4cc2363e615467a0d78035884819a61927bf61b323fe029"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
